{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:11:25.835955800Z",
     "start_time": "2024-07-11T02:11:23.502566300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from merge_script import modify_first_column\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import Calculate_Feature\n",
    "import os\n",
    "from spline import np_move_avg\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm, tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def use_pca(featuer_data, n_components=5):\n",
    "    pca = PCA(n_components)\n",
    "    axis_fea = pca.fit_transform(featuer_data)  # 每个样本降为n_components维\n",
    "    fea = []\n",
    "    for raw in range(axis_fea.shape[0]):\n",
    "        for ele in axis_fea[raw, :]:\n",
    "            fea.append(ele)\n",
    "    return fea\n",
    "\n",
    "\n",
    "def axis_normalization(datalist, stage=1):\n",
    "    normalized_data = []\n",
    "    #datalist = np.array(datalist)\n",
    "    for data in datalist:\n",
    "        maximum = max(data)\n",
    "        minimum = min(data)\n",
    "        # print(\"maximum is:\",maximum,\"minimum is:\",minimum)\n",
    "        normalized_data.append([(item - minimum) / (maximum - minimum) * stage for item in data])\n",
    "    return np.array(normalized_data)\n",
    "\n",
    "\n",
    "def three_fuse(data):\n",
    "    axis_num = int(data.shape[0] / 3)\n",
    "    f_nd = []\n",
    "\n",
    "    for f_in in range(axis_num):\n",
    "        nd = []\n",
    "        index = f_in * 3\n",
    "        for i in range(data.shape[1]):\n",
    "            d = data[:, i]\n",
    "            fuse_data = math.sqrt(d[index] * d[index] + d[index + 1] * d[index + 1] + d[index + 2] * d[index + 2])\n",
    "            nd.append(fuse_data)\n",
    "        f_nd.append(nd)\n",
    "    return f_nd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/Merge_fold/ByNum_spline3/0', 'datasets/Merge_fold/ByNum_spline3/1', 'datasets/Merge_fold/ByNum_spline3/2', 'datasets/Merge_fold/ByNum_spline3/3', 'datasets/Merge_fold/ByNum_spline3/4', 'datasets/Merge_fold/ByNum_spline4/0', 'datasets/Merge_fold/ByNum_spline4/1', 'datasets/Merge_fold/ByNum_spline4/2', 'datasets/Merge_fold/ByNum_spline4/3', 'datasets/Merge_fold/ByNum_spline4/4', 'datasets/Merge_fold/ByNum_spline5/0', 'datasets/Merge_fold/ByNum_spline5/1', 'datasets/Merge_fold/ByNum_spline5/2', 'datasets/Merge_fold/ByNum_spline5/3', 'datasets/Merge_fold/ByNum_spline5/4', 'datasets/USC-HAD-clean/Subject1', 'datasets/USC-HAD-clean/Subject2', 'datasets/USC-HAD-clean/Subject3', 'datasets/USC-HAD-clean/Subject4', 'datasets/USC-HAD-clean/Subject5', 'datasets/USC-HAD-clean/Subject6', 'datasets/USC-HAD-clean/Subject7', 'datasets/USC-HAD-clean/Subject8', 'datasets/USC-HAD-clean/Subject9', 'datasets/USC-HAD-clean/Subject10', 'datasets/USC-HAD-clean/Subject11', 'datasets/USC-HAD-clean/Subject12', 'datasets/USC-HAD-clean/Subject13', 'datasets/USC-HAD-clean/Subject14']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "l_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# l_svc = svm.SVC(C=1.0, kernel='rbf')\n",
    "l_svc = svm.SVC(C=1000, kernel='rbf')\n",
    "l_clftree = tree.DecisionTreeClassifier(criterion='entropy',random_state=42)\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "ID = range(1,15)\n",
    "real_total_file = []\n",
    "total_file = []\n",
    "\n",
    "real_path = 'datasets/USC-HAD-clean/Subject'\n",
    "jump_path_virtual3 = 'datasets/Merge_fold/ByNum_spline3/'\n",
    "jump_path_virtual4 = 'datasets/Merge_fold/ByNum_spline4/'\n",
    "jump_path_virtual5 = 'datasets/Merge_fold/ByNum_spline5/'\n",
    "\n",
    "# total_file.append(jump_path_virtual)\n",
    "\n",
    "for index in range(5):\n",
    "    total_file.append(jump_path_virtual3+str(index))\n",
    "    \n",
    "for index in range(5):\n",
    "    total_file.append(jump_path_virtual4+str(index))\n",
    "\n",
    "\n",
    "for index in range(5):\n",
    "    total_file.append(jump_path_virtual5+str(index))\n",
    "\n",
    "for index in ID:\n",
    "    total_file.append(real_path + str(index))\n",
    "print(total_file)\n",
    "print(len(total_file))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:11:25.850458500Z",
     "start_time": "2024-07-11T02:11:25.831867900Z"
    }
   },
   "id": "53c89287b4b7f21",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomLeaveOneOut:\n",
    "    def __init__(self, start=7, end=13):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.current = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current > self.end:\n",
    "            raise StopIteration\n",
    "        test_indices = [self.current]\n",
    "        train_indices = list(range(self.start, self.end + 1))\n",
    "        train_indices.remove(self.current)\n",
    "        self.current += 1\n",
    "        # return list(range(47)) + train_indices, test_indices\n",
    "        # return train_indices, test_indices\n",
    "        # return list(range(8,9))+ list(range(2,6)), test_indices\n",
    "        # return list(range(3,5)) + list(range(1)) + list(range(6,7)), test_indices\n",
    "        return list(range(5,15)) + train_indices, test_indices\n",
    "        # return list(range(15)) + train_indices, test_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:28:59.981397700Z",
     "start_time": "2024-07-11T02:28:59.960050600Z"
    }
   },
   "id": "5a434d9db67349b3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28] [15]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject1\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28] [16]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject2\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28] [17]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject3\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28] [18]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject4\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28] [19]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject5\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28] [20]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject6\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28] [21]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject7\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28] [22]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject8\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28] [23]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject9\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28] [24]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject10\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28] [25]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject11\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28] [26]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject12\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28] [27]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject13\n",
      "test sample size is: (15, 9)\n",
      "*****\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27] [28]\n",
      "real sample size is: (575, 9)\n",
      "datasets/USC-HAD-clean/Subject14\n",
      "test sample size is: (15, 9)\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 1-WALK 6-RUN 7-JUMP 8-SIT \"\"\"\n",
    "# Real_motion_type = ['a1t', 'a6t', 'a7t', 'a8t']\n",
    "# Real_motion_type = ['a1t', 'a7t', 'a8t'] # a little\n",
    "Real_motion_type = ['a6t', 'a7t', 'a8t'] # a little\n",
    "# encode_feauture = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0] # a little\n",
    "encode_feauture = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
    "label = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "loo = CustomLeaveOneOut(start=15, end=28)\n",
    "# loo = CustomLeaveOneOut(start=7, end=13)\n",
    "# loo = CustomLeaveOneOut(start=14, end=20)\n",
    "# loo = CustomLeaveOneOut(start=8, end=14)\n",
    "# loo = CustomLeaveOneOut(start=40, end=46)\n",
    "rf_predicted = []\n",
    "svm_predicted = []\n",
    "decisiontree_predicted = []\n",
    "label_save_list = []\n",
    "predict_SVM_save_list = []\n",
    "predict_RF_save_list = []\n",
    "predict_DT_save_list = []\n",
    "\n",
    "\n",
    "# for train_index, test_index in loo.split(total_file):\n",
    "#     print(train_index,test_index)\n",
    "for train_index, test_index in loo:\n",
    "    print(train_index,test_index)\n",
    "    Data_X = []\n",
    "    Label_X = []\n",
    "    TestData_X = []\n",
    "    TestLabel_X = []\n",
    "    true_label = []\n",
    "    for tmtrain in train_index:\n",
    "        # print(tmtrain)\n",
    "        subject = total_file[tmtrain]  # for each subject\n",
    "        # print(subject)\n",
    "        #subject_file = glob.glob(os.path.join(subject,'*.csv'))\n",
    "        for i in range(len(Real_motion_type)):\n",
    "            motion = Real_motion_type[i]\n",
    "            motion_file = glob.glob(os.path.join(subject + '/' + '*' + motion + '*', '*.csv'))\n",
    "            # motion_file = os.path.join(subject + '/' + 'motion', '*.csv')\n",
    "            # motion_file = glob.glob(os.path.join(subject + '/' + 'motion/', '*.csv'))\n",
    "            # print(subject + '/' +  motion )\n",
    "            # print(motion_file)\n",
    "            for motion_frame in motion_file:\n",
    "                #print(motion_frame)\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [3,4,5,6,7,8,9,10,11,12,13,14])\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9,10,11,12,13,14])#1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = pd.read_csv(motion_frame, index_col=0, header=0, usecols= [0,1,2,3])#0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9])#0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = np.array(df).T\n",
    "\n",
    "\n",
    "                # timestamp = []\n",
    "                # for t in range(df.shape[1]):\n",
    "                #     timestamp.append(t*0.05)\n",
    "                # timestamp = np.array(timestamp)\n",
    "\n",
    "                # for k in range(df.shape[0]):\n",
    "                #     df[k, :] = np_move_avg(df[k, :], 15, mode='same')\n",
    "\n",
    "                # fuse three axis-data\n",
    "                fuse_df = three_fuse(df)\n",
    "                nor_df = axis_normalization(fuse_df)  #.tolist()\n",
    "                # nor_df = axis_normalization(df)  #.tolist()\n",
    "\n",
    "                axis_fea = []\n",
    "                # rd = []\n",
    "                # print(nor_df.shape)\n",
    "                for raw in range(nor_df.shape[0]):\n",
    "                # for raw in range(df.shape[0]):\n",
    "                    tmd = nor_df[raw, :]\n",
    "\n",
    "                    # resampling = spline.spline_cal(timestamp,tmd.tolist(),10)\n",
    "                    #\n",
    "                    # tmd = resampling.resample()\n",
    "                    # print(tmd)\n",
    "\n",
    "                    # tmd = df[raw, :]\n",
    "                    # rd.append(tmd)\n",
    "                    cal_fea = Calculate_Feature.Get_Feature(tmd, encode_feauture)\n",
    "                    fea = cal_fea.cal_result()\n",
    "                    for f in fea:\n",
    "                        axis_fea.append(f)\n",
    "\n",
    "                # print(axis_fea)\n",
    "\n",
    "                Data_X.append(axis_fea)\n",
    "                Label_X.append(label[i])\n",
    "\n",
    "                # print(Label_X)\n",
    "\n",
    "    Real_Data = np.array(Data_X)\n",
    "    Real_Label = np.array(Label_X)\n",
    "    # print(Real_Data.shape)\n",
    "    # print(Real_Label.shape)\n",
    "\n",
    "    # for i in range(Real_Data.shape[0]):\n",
    "    #     Real_Data[i] = [0 if math.isnan(x) else x for x in Real_Data[i]]\n",
    "    # print(\"real sample size before PCA is:\", Real_Data.shape)\n",
    "    #\n",
    "    # pca = PCA(2)\n",
    "    # Real_Data = pca.fit_transform(Real_Data)\n",
    "\n",
    "    # tsne = TSNE(2)\n",
    "    # Real_Data = tsne.fit_transform(Real_Data)\n",
    "\n",
    "    print(\"real sample size is:\", Real_Data.shape)\n",
    "    l_rf.fit(Real_Data, Real_Label)\n",
    "    l_svc.fit(Real_Data, Real_Label)\n",
    "    l_clftree.fit(Real_Data, Real_Label)\n",
    "\n",
    "    for tmtest in test_index:\n",
    "        # print(tmtest)\n",
    "        subject = total_file[tmtest]  # for each subject\n",
    "        print(subject)\n",
    "        #subject_file = glob.glob(os.path.join(subject,'*.csv'))\n",
    "        for i in range(len(Real_motion_type)):\n",
    "            motion = Real_motion_type[i]\n",
    "            motion_file = glob.glob(os.path.join(subject + '/' + '*' + motion + '*', '*.csv'))\n",
    "            for motion_frame in motion_file:\n",
    "                #print(motion_frame)\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [3,4,5,6,7,8,9,10,11,12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = pd.read_csv(motion_frame, index_col=0, header=0, usecols= [0,1,2,3])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [9])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [9,10,11,12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None)  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = np.array(df).T\n",
    "\n",
    "\n",
    "                # timestamp = []\n",
    "                # for t in range(df.shape[1]):\n",
    "                #     timestamp.append(t*0.05)\n",
    "                # timestamp = np.array(timestamp)\n",
    "\n",
    "                #\n",
    "                # for k in range(df.shape[0]):\n",
    "                #     df[k, :] = np_move_avg(df[k, :], 20, mode='same')\n",
    "\n",
    "                #fuse three axis-data\n",
    "                fuse_df = three_fuse(df)\n",
    "                nor_df = axis_normalization(fuse_df)  #.tolist()\n",
    "                # nor_df = axis_normalization(df)  #.tolist()\n",
    "\n",
    "                axis_fea = []\n",
    "                # rd = []\n",
    "                for raw in range(nor_df.shape[0]):\n",
    "                # for raw in range(df.shape[0]):\n",
    "                    tmd = nor_df[raw, :]\n",
    "                    # tmd = df[raw, :]\n",
    "\n",
    "\n",
    "                    # resampling = spline.spline_cal(timestamp,tmd.tolist(),10)\n",
    "                    #\n",
    "                    # tmd = resampling.resample()\n",
    "\n",
    "\n",
    "                    # rd.append(tmd)\n",
    "                    cal_fea = Calculate_Feature.Get_Feature(tmd, encode_feauture)\n",
    "                    fea = cal_fea.cal_result()\n",
    "                    for f in fea:\n",
    "                        axis_fea.append(f)\n",
    "\n",
    "\n",
    "\n",
    "                TestData_X.append(axis_fea)\n",
    "                TestLabel_X.append(label[i])\n",
    "\n",
    "\n",
    "    TestData = np.array(TestData_X)\n",
    "\n",
    "    # for i in range(TestData.shape[0]):\n",
    "    #     TestData[i] = [0 if math.isnan(x) else x for x in TestData[i]]\n",
    "\n",
    "    TestLabel = np.array(TestLabel_X)\n",
    "    label_save_list.append(TestLabel)\n",
    "\n",
    "    # print(\"test sample size before PCA is:\", TestData.shape)\n",
    "\n",
    "    # pca = PCA(2)\n",
    "    # TestData = pca.fit_transform(TestData)\n",
    "\n",
    "    # tsne = TSNE(2)\n",
    "    # TestData = tsne.fit_transform(TestData)\n",
    "\n",
    "    print(\"test sample size is:\", TestData.shape)\n",
    "\n",
    "\n",
    "    predict_RF_save_list.append(l_rf.predict(TestData))\n",
    "    predict_SVM_save_list.append(l_svc.predict(TestData))\n",
    "    predict_DT_save_list.append(l_clftree.predict(TestData))\n",
    "\n",
    "\n",
    "    rf_predicted.append(accuracy_score(TestLabel, l_rf.predict(TestData)))\n",
    "    svm_predicted.append(accuracy_score(TestLabel, l_svc.predict(TestData)))\n",
    "    decisiontree_predicted.append(accuracy_score(TestLabel, l_clftree.predict(TestData)))\n",
    "\n",
    "    #true_label.append(TestLabel_X[0])\n",
    "\n",
    "    print(\"*****\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:29:42.741903400Z",
     "start_time": "2024-07-11T02:29:00.890704600Z"
    }
   },
   "id": "644820e52019dbcc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333]\n",
      "[1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 0.6666666666666666, 0.8666666666666667, 1.0, 1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 0.7333333333333333]\n",
      "0.980952380952381\n",
      "0.9857142857142858\n",
      "0.9238095238095239\n"
     ]
    }
   ],
   "source": [
    "print(rf_predicted)\n",
    "print(svm_predicted)\n",
    "print(decisiontree_predicted)\n",
    "print(sum(rf_predicted) / len(rf_predicted))\n",
    "print(sum(svm_predicted) / len(svm_predicted))\n",
    "print(sum(decisiontree_predicted) / len(decisiontree_predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:29:42.776448700Z",
     "start_time": "2024-07-11T02:29:42.744295600Z"
    }
   },
   "id": "b43cec4d83e8e4e8",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
