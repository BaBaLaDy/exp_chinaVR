{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:15:21.617808200Z",
     "start_time": "2024-05-21T14:15:21.606177Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from merge_script import modify_first_column\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import Calculate_Feature\n",
    "import os\n",
    "from spline import np_move_avg\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm, tree\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def use_pca(featuer_data, n_components=5):\n",
    "    pca = PCA(n_components)\n",
    "    axis_fea = pca.fit_transform(featuer_data)  # 每个样本降为n_components维\n",
    "    fea = []\n",
    "    for raw in range(axis_fea.shape[0]):\n",
    "        for ele in axis_fea[raw, :]:\n",
    "            fea.append(ele)\n",
    "    return fea\n",
    "\n",
    "\n",
    "def axis_normalization(datalist, stage=1):\n",
    "    normalized_data = []\n",
    "    #datalist = np.array(datalist)\n",
    "    for data in datalist:\n",
    "        maximum = max(data)\n",
    "        minimum = min(data)\n",
    "        # print(\"maximum is:\",maximum,\"minimum is:\",minimum)\n",
    "        normalized_data.append([(item - minimum) / (maximum - minimum) * stage for item in data])\n",
    "    return np.array(normalized_data)\n",
    "\n",
    "\n",
    "def three_fuse(data):\n",
    "    axis_num = int(data.shape[0] / 3)\n",
    "    f_nd = []\n",
    "\n",
    "    for f_in in range(axis_num):\n",
    "        nd = []\n",
    "        index = f_in * 3\n",
    "        for i in range(data.shape[1]):\n",
    "            d = data[:, i]\n",
    "            fuse_data = math.sqrt(d[index] * d[index] + d[index + 1] * d[index + 1] + d[index + 2] * d[index + 2])\n",
    "            nd.append(fuse_data)\n",
    "        f_nd.append(nd)\n",
    "    return f_nd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['CorData-Seg/scale_0123_spline3_240/0.5', 'CorData-Seg/scale_0123_pline4_240/0.5', 'CorData-Seg/scale_0123_spline5_240/0.5', 'CorData-Seg/scale_0123_spline3_240/0.7', 'CorData-Seg/scale_0123_pline4_240/0.7', 'CorData-Seg/scale_0123_spline5_240/0.7', 'CorData-Seg/scale_0123_spline3_240/1.3', 'CorData-Seg/scale_0123_pline4_240/1.3', 'CorData-Seg/scale_0123_spline5_240/1.3', 'CorData-Seg/scale_0123_spline3_240/1.5', 'CorData-Seg/scale_0123_pline4_240/1.5', 'CorData-Seg/scale_0123_spline5_240/1.5', 'CorData-Seg/scale_0123_trans_spline3_240/0.5', 'CorData-Seg/scale_0123_trans_spline4_240/0.5', 'CorData-Seg/scale_0123_trans_spline5_240/0.5', 'CorData-Seg/scale_0123_trans_spline3_240/0.7', 'CorData-Seg/scale_0123_trans_spline4_240/0.7', 'CorData-Seg/scale_0123_trans_spline5_240/0.7', 'CorData-Seg/scale_0123_trans_spline3_240/1.3', 'CorData-Seg/scale_0123_trans_spline4_240/1.3', 'CorData-Seg/scale_0123_trans_spline5_240/1.3', 'CorData-Seg/scale_0123_trans_spline3_240/1.5', 'CorData-Seg/scale_0123_trans_spline4_240/1.5', 'CorData-Seg/scale_0123_trans_spline5_240/1.5', 'save_data/Animation_record_pos_data_spline5_120', 'save_data/RealData_Seg_byName/Effy', 'save_data/RealData_Seg_byName/Leafy', 'save_data/RealData_Seg_byName/Nick', 'save_data/RealData_Seg_byName/Qin', 'save_data/RealData_Seg_byName/Tonii', 'save_data/RealData_Seg_byName/Xu', 'save_data/RealData_Seg_byName/Yamamoto']\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# l_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "l_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "l_svc = svm.SVC(C=1.0, kernel='rbf')\n",
    "# l_svc = svm.SVC(C=1000, kernel='rbf')\n",
    "l_clftree = tree.DecisionTreeClassifier(criterion='entropy',random_state=42)\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "\n",
    "real_path = 'save_data/12-16-Realdataset-Xia/Dataset-ID-'\n",
    "\n",
    "ID = [1, 2, 3, 4, 5, 6, 7]\n",
    "label = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# Real_data_path = \"save_data/RealData_Seg_byName_120/\"\n",
    "Real_data_path = \"save_data/RealData_Seg_byName/\"\n",
    "\n",
    "virtual_data_path = \"save_data/Pos_New_New_Virtual_Seg_byScale_xy_spline5_120/\" # awsome !!!\n",
    "virtual_data_path_2 = \"save_data/Pos_New_New_Virtual_Seg_byScale_xy_18_spline3_60/\" # awsome !!!\n",
    "\n",
    "# virtual_data_path_2 = \"save_data/Virtual_New_Conv_0108_size7_spline3_240/\"\n",
    "virtual_data_path_3 = \"save_data/Virtual_New_Conv_0108_size7_spline4_240/\"\n",
    "# virtual_data_path_4 = \"save_data/Virtual_New_Conv_0108_size7_spline5_240/\"\n",
    "\n",
    "virtual_data_path_4 = [\"save_data/Virtual_New_Conv_0108_size3_spline3_240/\", \"save_data/Virtual_New_Conv_0108_size3_spline5_240/\", \"save_data/Virtual_New_Conv_0108_size3_spline7_240/\"]\n",
    "\n",
    "virtual_data_path_5 = [\"save_data/Virtual_New_Conv_0108_size5_spline3_240/\", \"save_data/Virtual_New_Conv_0108_size5_spline5_240/\", \"save_data/Virtual_New_Conv_0108_size5_spline7_240/\"]\n",
    "\n",
    "virtual_data_path_6 = [\"save_data/Virtual_New_Conv_0108_size7_spline3_240/\", \"save_data/Virtual_New_Conv_0108_size7_spline5_240/\", \"save_data/Virtual_New_Conv_0108_size7_spline7_240/\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "virtual_data_path_7 = [\"save_data/Virtual_New_Conv_0108_concave_spline3_240/\",\"save_data/Virtual_New_Conv_0108_concave_spline4_240/\",\"save_data/Virtual_New_Conv_0108_concave_spline5_240/\"]\n",
    "virtual_data_path_8 = [\"save_data/Virtual_New_Conv_0108_convex_spline3_240/\",\"save_data/Virtual_New_Conv_0108_convex_spline4_240/\",\"save_data/Virtual_New_Conv_0108_convex_spline5_240/\"]\n",
    "virtual_data_path_9 = [\"save_data/Virtual_New_Conv_0108_inc_spline3_240/\",\"save_data/Virtual_New_Conv_0108_inc_spline4_240/\",\"save_data/Virtual_New_Conv_0108_inc_spline5_240/\"]\n",
    "virtual_data_path_10 = [\"save_data/Virtual_New_Conv_0108_dec_spline3_240/\",\"save_data/Virtual_New_Conv_0108_dec_spline4_240/\",\"save_data/Virtual_New_Conv_0108_dec_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_11 = [\"save_data/Virtual_New_Conv_1230_spline3_240/\",\"save_data/Virtual_New_Conv_1230_spline4_240/\",\"save_data/Virtual_New_Conv_1230_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_12 = [\"save_data/Virtual_New_Conv_1231_spline3_240/\",\"save_data/Virtual_New_Conv_1231_spline4_240/\",\"save_data/Virtual_New_Conv_1231_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_size3 = [\"CorData-seg/Virtual_New_Conv_0115_size3_spline3_240/\",\"CorData-seg/Virtual_New_Conv_0115_size3_spline4_240/\",\"CorData-seg/Virtual_New_Conv_0115_size3_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_size3_t = [\"CorData-Seg/Virtual_New_Conv_0115_size3_trans_spline3_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size3_trans_spline4_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size3_trans_spline5_240/\"]\n",
    "\n",
    "\n",
    "virtual_data_path_size5 = [\"CorData-seg/Virtual_New_Conv_0115_size5_spline3_240/\",\"CorData-seg/Virtual_New_Conv_0115_size5_spline4_240/\",\"CorData-seg/Virtual_New_Conv_0115_size5_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_size5_t = [\"CorData-Seg/Virtual_New_Conv_0115_size5_trans_spline3_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size5_trans_spline4_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size5_trans_spline5_240/\"]\n",
    "\n",
    "\n",
    "virtual_data_path_size7 = [\"CorData-seg/Virtual_New_Conv_0115_size7_spline3_240/\",\"CorData-seg/Virtual_New_Conv_0115_size7_spline4_240/\",\"CorData-seg/Virtual_New_Conv_0115_size7_spline5_240/\"]\n",
    "\n",
    "virtual_data_path_size7_t = [\"CorData-Seg/Virtual_New_Conv_0115_size7_trans_spline3_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size7_trans_spline4_240/\",\"CorData-Seg/Virtual_New_Conv_0115_size7_trans_spline5_240/\"]\n",
    "\n",
    "\n",
    "virtual_data_path_scale_t = [\"CorData-Seg/scale_0123_trans_spline3_240/\", \"CorData-Seg/scale_0123_trans_spline4_240/\", \"CorData-Seg/scale_0123_trans_spline5_240/\"]\n",
    "virtual_data_path_scale = [\"CorData-Seg/scale_0123_spline3_240/\", \"CorData-Seg/scale_0123_pline4_240/\", \"CorData-Seg/scale_0123_spline5_240/\"]\n",
    "\n",
    "ori_data_path_2 = \"save_data/Animation_record_pos_data_spline5_120\"\n",
    "# ori_data_path_2 = \"save_data/Ori_motion_pos_data_spline5_120\"\n",
    "\n",
    "ori_data_path = 'save_data/Conv_Motion_acc_data_spline3_240/'\n",
    "\n",
    "\n",
    "\n",
    "virtual_motion_type = ['ankleTap', 'highKnee', 'reverseLunge', 'sideCrunch', 'sidetoside']\n",
    "\n",
    "motion_name = ['ankle', 'highKnee', 'Kneekick', 'reverseLunge', 'sideCrunch', 'sidetoside', 'warmup']\n",
    "\n",
    "human_name = [\"Effy\", \"Leafy\", \"Nick\", \"Qin\", \"Tonii\", \"Xu\", \"Yamamoto\"]\n",
    "# human_name = [\"Effy\", \"Leafy\", \"Nick\", \"Qin\", \"Xu\", \"Yamamoto\"]\n",
    "# scale_list = [\"0.8\", \"0.9\", \"1.1\",\"1.3\", \"1.2\"]\n",
    "# scale_list = [\"0.5\", \"0.7\", \"0.8\",\"0.9\", \"1.1\", \"1.2\",\"1.3\", \"1.5\"]\n",
    "scale_list = [\"0.5\", \"0.7\", \"0.9\", \"1.1\", \"1.3\", \"1.5\"]\n",
    "scale_list_2 = [\"0.5\", \"0.7\", \"1.3\", \"1.5\"]\n",
    "# scale_list_2 = [\"0.5\", \"1.5\"]\n",
    "# scale_list = [\"0.7\", \"0.9\", \"1.1\", \"1.3\", \"1.5\"]\n",
    "scale_list_conv = [\"0\", \"1\", \"2\", \"3\"]\n",
    "scale_list_conv_2 = [\"0\", \"1\", \"2\"]\n",
    "scale_list_conv_3 = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "virtual_total_file = []\n",
    "real_total_file = []\n",
    "total_file = []\n",
    "\n",
    "# amplitude\n",
    "# for scale in scale_list:\n",
    "#     virtual_total_file.append(virtual_data_path + scale)\n",
    "#     total_file.append(virtual_data_path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     virtual_total_file.append(virtual_data_path_2 + scale)\n",
    "#     total_file.append(virtual_data_path_2 + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     virtual_total_file.append(virtual_data_path_3 + scale)\n",
    "#     total_file.append(virtual_data_path_3 + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     virtual_total_file.append(virtual_data_path_4 + scale)\n",
    "#     total_file.append(virtual_data_path_4 + scale)\n",
    "# \n",
    "# \n",
    "# for path in virtual_data_path_4:\n",
    "#     for scale in scale_list_conv:\n",
    "#             virtual_total_file.append(path + scale)\n",
    "#             total_file.append(path + scale)\n",
    "# \n",
    "# for path in virtual_data_path_5:\n",
    "#     for scale in scale_list_conv:\n",
    "#             virtual_total_file.append(path + scale)\n",
    "#             total_file.append(path + scale)\n",
    "# \n",
    "# for path in virtual_data_path_6:\n",
    "#     for scale in scale_list_conv:\n",
    "#             virtual_total_file.append(path + scale)\n",
    "#             total_file.append(path + scale)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_7:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "    \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_8:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "\n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_9:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_10:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_11:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "\n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size3:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size3_t:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size5:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size5_t:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size7:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_conv:\n",
    "#     for path in virtual_data_path_size7_t:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# 0 -  24 - Factor\n",
    "for scale in scale_list_2:\n",
    "    for path in virtual_data_path_scale:\n",
    "        virtual_total_file.append(path + scale)\n",
    "        total_file.append(path + scale)\n",
    "\n",
    "for scale in scale_list_2:\n",
    "    for path in virtual_data_path_scale_t:\n",
    "        virtual_total_file.append(path + scale)\n",
    "        total_file.append(path + scale)\n",
    "\n",
    "# ori\n",
    "total_file.append(ori_data_path_2)\n",
    "# total_file.append(ori_data_path)\n",
    "print(len(total_file))\n",
    "# for index in ID:\n",
    "#     real_total_file.append(real_path + str(index))\n",
    "#     total_file.append(real_path + str(index))\n",
    "\n",
    "for name in human_name:\n",
    "    real_total_file.append(Real_data_path + name)\n",
    "    total_file.append(Real_data_path + name)\n",
    "print(total_file)\n",
    "\n",
    "print(len(total_file))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:02.641254600Z",
     "start_time": "2024-05-21T14:25:02.631548200Z"
    }
   },
   "id": "a4429638f4d2a7fc",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomLeaveOneOut:\n",
    "    def __init__(self, start=7, end=13):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.current = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current > self.end:\n",
    "            raise StopIteration\n",
    "        test_indices = [self.current]\n",
    "        train_indices = list(range(self.start, self.end + 1))\n",
    "        train_indices.remove(self.current)\n",
    "        self.current += 1\n",
    "        # return list(range(47)) + train_indices, test_indices\n",
    "        # return train_indices, test_indices\n",
    "\n",
    "        # return list(range(12))+ list(range(36,48)), test_indices\n",
    "\n",
    "        # return list(range(3,5)) + list(range(1)) + list(range(6,7)), test_indices\n",
    "        # return train_indices, test_indices\n",
    "        return list(range(24, 25)), test_indices\n",
    "\n",
    "# 0 -  24 - Factor\n",
    "# for scale in scale_list_2:\n",
    "#     for path in virtual_data_path_scale:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "# \n",
    "# for scale in scale_list_2:\n",
    "#     for path in virtual_data_path_scale_t:\n",
    "#         virtual_total_file.append(path + scale)\n",
    "#         total_file.append(path + scale)\n",
    "\n",
    "\n",
    "# loo = CustomLeaveOneOut(start=6, end=11)\n",
    "#\n",
    "# for train_indices, test_indices in loo:\n",
    "#     print(\"Train Indices:\", train_indices)\n",
    "#     print(\"Test Indices:\", test_indices)\n",
    "\n",
    "\n",
    "Real_motion_type = ['ReverseLunge','HighKnee','sidetoside'] # 相同awsome!!!!!!!!!!!\n",
    "\n",
    "encode_feauture = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
    "# encode_feauture = [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:11.043442700Z",
     "start_time": "2024-05-21T14:25:11.031051900Z"
    }
   },
   "id": "54146074478af6b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24] [25]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Effy\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [26]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Leafy\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [27]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Nick\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [28]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Qin\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [29]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Tonii\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [30]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Xu\n",
      "test sample size is: (66, 9)\n",
      "*****\n",
      "[24] [31]\n",
      "real sample size is: (73, 9)\n",
      "save_data/RealData_Seg_byName/Yamamoto\n",
      "test sample size is: (66, 9)\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "# loo = CustomLeaveOneOut(start=1, end=7)\n",
    "# loo = CustomLeaveOneOut(start=7, end=13)\n",
    "# loo = CustomLeaveOneOut(start=14, end=20)\n",
    "# loo = CustomLeaveOneOut(start=18, end=24) \n",
    "loo = CustomLeaveOneOut(start=25, end=31)\n",
    "rf_predicted = []\n",
    "svm_predicted = []\n",
    "decisiontree_predicted = []\n",
    "label_save_list = []\n",
    "predict_SVM_save_list = []\n",
    "predict_RF_save_list = []\n",
    "predict_DT_save_list = []\n",
    "\n",
    "\n",
    "# for train_index, test_index in loo.split(total_file):\n",
    "#     print(train_index,test_index)\n",
    "for train_index, test_index in loo:\n",
    "    print(train_index,test_index)\n",
    "    Data_X = []\n",
    "    Label_X = []\n",
    "    TestData_X = []\n",
    "    TestLabel_X = []\n",
    "    true_label = []\n",
    "    for tmtrain in train_index:\n",
    "        # print(tmtrain)\n",
    "        subject = total_file[tmtrain]  # for each subject\n",
    "        # print(subject)\n",
    "        #subject_file = glob.glob(os.path.join(subject,'*.csv'))\n",
    "        for i in range(len(Real_motion_type)):\n",
    "            motion = Real_motion_type[i]\n",
    "            motion_file = glob.glob(os.path.join(subject + '/' + '*' + motion + '*', '*.csv'))\n",
    "            # motion_file = os.path.join(subject + '/' + 'motion', '*.csv')\n",
    "            # motion_file = glob.glob(os.path.join(subject + '/' + 'motion/', '*.csv'))\n",
    "            # print(subject + '/' +  motion )\n",
    "            # print(motion_file)\n",
    "            for motion_frame in motion_file:\n",
    "                #print(motion_frame)\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [3,4,5,6,7,8,9,10,11,12,13,14])\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9,10,11,12,13,14])#1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9,10,11])#0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9])#0,1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = np.array(df).T\n",
    "\n",
    "\n",
    "                # timestamp = []\n",
    "                # for t in range(df.shape[1]):\n",
    "                #     timestamp.append(t*0.05)\n",
    "                # timestamp = np.array(timestamp)\n",
    "\n",
    "                # for k in range(df.shape[0]):\n",
    "                #     df[k, :] = np_move_avg(df[k, :], 15, mode='same')\n",
    "\n",
    "                # fuse three axis-data\n",
    "                fuse_df = three_fuse(df)\n",
    "                nor_df = axis_normalization(fuse_df)  #.tolist()\n",
    "                # nor_df = axis_normalization(df)  #.tolist()\n",
    "\n",
    "                axis_fea = []\n",
    "                # rd = []\n",
    "                # print(nor_df.shape)\n",
    "                for raw in range(nor_df.shape[0]):\n",
    "                # for raw in range(df.shape[0]):\n",
    "                    tmd = nor_df[raw, :]\n",
    "\n",
    "                    # resampling = spline.spline_cal(timestamp,tmd.tolist(),10)\n",
    "                    #\n",
    "                    # tmd = resampling.resample()\n",
    "                    # print(tmd)\n",
    "\n",
    "                    # tmd = df[raw, :]\n",
    "                    # rd.append(tmd)\n",
    "                    cal_fea = Calculate_Feature.Get_Feature(tmd, encode_feauture)\n",
    "                    fea = cal_fea.cal_result()\n",
    "                    for f in fea:\n",
    "                        axis_fea.append(f)\n",
    "\n",
    "                # print(axis_fea)\n",
    "\n",
    "                Data_X.append(axis_fea)\n",
    "                Label_X.append(label[i])\n",
    "\n",
    "                # print(Label_X)\n",
    "\n",
    "    Real_Data = np.array(Data_X)\n",
    "    Real_Label = np.array(Label_X)\n",
    "    # print(Real_Data.shape)\n",
    "    # print(Real_Label.shape)\n",
    "\n",
    "    # for i in range(Real_Data.shape[0]):\n",
    "    #     Real_Data[i] = [0 if math.isnan(x) else x for x in Real_Data[i]]\n",
    "    # print(\"real sample size before PCA is:\", Real_Data.shape)\n",
    "    #\n",
    "    # pca = PCA(2)\n",
    "    # Real_Data = pca.fit_transform(Real_Data)\n",
    "\n",
    "    # tsne = TSNE(2)\n",
    "    # Real_Data = tsne.fit_transform(Real_Data)\n",
    "\n",
    "    print(\"real sample size is:\", Real_Data.shape)\n",
    "    l_rf.fit(Real_Data, Real_Label)\n",
    "    l_svc.fit(Real_Data, Real_Label)\n",
    "    l_clftree.fit(Real_Data, Real_Label)\n",
    "\n",
    "    for tmtest in test_index:\n",
    "        # print(tmtest)\n",
    "        subject = total_file[tmtest]  # for each subject\n",
    "        print(subject)\n",
    "        #subject_file = glob.glob(os.path.join(subject,'*.csv'))\n",
    "        for i in range(len(Real_motion_type)):\n",
    "            motion = Real_motion_type[i]\n",
    "            motion_file = glob.glob(os.path.join(subject + '/' + '*' + motion + '*', '*.csv'))\n",
    "            for motion_frame in motion_file:\n",
    "                #print(motion_frame)\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [3,4,5,6,7,8,9,10,11,12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [9,10,11])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [9])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None,  usecols= [9,10,11,12,13,14])  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                # df = pd.read_csv(motion_frame, index_col=False, header=None)  #1,2,3,4,5,6,7,8,9,10,11,12\n",
    "                df = np.array(df).T\n",
    "\n",
    "\n",
    "                # timestamp = []\n",
    "                # for t in range(df.shape[1]):\n",
    "                #     timestamp.append(t*0.05)\n",
    "                # timestamp = np.array(timestamp)\n",
    "\n",
    "                #\n",
    "                # for k in range(df.shape[0]):\n",
    "                #     df[k, :] = np_move_avg(df[k, :], 20, mode='same')\n",
    "\n",
    "                #fuse three axis-data\n",
    "                fuse_df = three_fuse(df)\n",
    "                nor_df = axis_normalization(fuse_df)  #.tolist()\n",
    "                # nor_df = axis_normalization(df)  #.tolist()\n",
    "\n",
    "                axis_fea = []\n",
    "                # rd = []\n",
    "                for raw in range(nor_df.shape[0]):\n",
    "                # for raw in range(df.shape[0]):\n",
    "                    tmd = nor_df[raw, :]\n",
    "                    # tmd = df[raw, :]\n",
    "\n",
    "\n",
    "                    # resampling = spline.spline_cal(timestamp,tmd.tolist(),10)\n",
    "                    #\n",
    "                    # tmd = resampling.resample()\n",
    "\n",
    "\n",
    "                    # rd.append(tmd)\n",
    "                    cal_fea = Calculate_Feature.Get_Feature(tmd, encode_feauture)\n",
    "                    fea = cal_fea.cal_result()\n",
    "                    for f in fea:\n",
    "                        axis_fea.append(f)\n",
    "\n",
    "\n",
    "\n",
    "                TestData_X.append(axis_fea)\n",
    "                TestLabel_X.append(label[i])\n",
    "\n",
    "\n",
    "    TestData = np.array(TestData_X)\n",
    "\n",
    "    # for i in range(TestData.shape[0]):\n",
    "    #     TestData[i] = [0 if math.isnan(x) else x for x in TestData[i]]\n",
    "\n",
    "    TestLabel = np.array(TestLabel_X)\n",
    "    label_save_list.append(TestLabel)\n",
    "\n",
    "    # print(\"test sample size before PCA is:\", TestData.shape)\n",
    "\n",
    "    # pca = PCA(2)\n",
    "    # TestData = pca.fit_transform(TestData)\n",
    "\n",
    "    # tsne = TSNE(2)\n",
    "    # TestData = tsne.fit_transform(TestData)\n",
    "\n",
    "    print(\"test sample size is:\", TestData.shape)\n",
    "\n",
    "\n",
    "    predict_RF_save_list.append(l_rf.predict(TestData))\n",
    "    predict_SVM_save_list.append(l_svc.predict(TestData))\n",
    "    predict_DT_save_list.append(l_clftree.predict(TestData))\n",
    "\n",
    "\n",
    "    rf_predicted.append(accuracy_score(TestLabel, l_rf.predict(TestData)))\n",
    "    svm_predicted.append(accuracy_score(TestLabel, l_svc.predict(TestData)))\n",
    "    decisiontree_predicted.append(accuracy_score(TestLabel, l_clftree.predict(TestData)))\n",
    "\n",
    "    #true_label.append(TestLabel_X[0])\n",
    "\n",
    "    print(\"*****\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:17.364938600Z",
     "start_time": "2024-05-21T14:25:12.930505900Z"
    }
   },
   "id": "8f98fbc62c150c64",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9090909090909091, 0.4090909090909091, 0.2878787878787879, 0.5, 0.5151515151515151, 0.3484848484848485, 0.5]\n",
      "[0.9393939393939394, 0.6666666666666666, 0.07575757575757576, 0.3787878787878788, 0.19696969696969696, 0.48484848484848486, 0.5]\n",
      "[0.5, 0.5454545454545454, 0.2727272727272727, 0.5454545454545454, 0.5757575757575758, 0.4090909090909091, 0.6212121212121212]\n",
      "0.49567099567099565\n",
      "0.4632034632034632\n",
      "0.49567099567099565\n"
     ]
    }
   ],
   "source": [
    "print(rf_predicted)\n",
    "print(svm_predicted)\n",
    "print(decisiontree_predicted)\n",
    "print(sum(rf_predicted) / len(rf_predicted))\n",
    "print(sum(svm_predicted) / len(svm_predicted))\n",
    "print(sum(decisiontree_predicted) / len(decisiontree_predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T14:25:26.468208500Z",
     "start_time": "2024-05-21T14:25:26.457922200Z"
    }
   },
   "id": "ce92bd4037d37954",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "ori\n",
    "0.632034632034632\n",
    "0.6147186147186147\n",
    "0.5909090909090909\n",
    "\n",
    "size3\n",
    "0.70995670995671\n",
    "0.6515151515151515\n",
    "0.7056277056277055\n",
    "\n",
    "size5\n",
    "0.6731601731601732\n",
    "0.6818181818181818\n",
    "0.5995670995670996\n",
    "\n",
    "size7\n",
    "0.6731601731601732\n",
    "0.6212121212121212\n",
    "0.683982683982684\n",
    "\n",
    "size5+7\n",
    "0.6904761904761905\n",
    "0.7337662337662338\n",
    "0.6450216450216449\n",
    "\n",
    "size3+5+7\n",
    "0.7229437229437229\n",
    "0.7402597402597404\n",
    "0.6363636363636364\n",
    "\n",
    "size3+7\n",
    "0.7012987012987012\n",
    "0.7034632034632036\n",
    "0.7142857142857143\n",
    "\n",
    "concave\n",
    "0.6883116883116882\n",
    "0.6688311688311688\n",
    "0.670995670995671\n",
    "\n",
    "convex\n",
    "0.6450216450216449\n",
    "0.6385281385281385\n",
    "0.5584415584415584\n",
    "\n",
    "inc\n",
    "0.6991341991341992\n",
    "0.6688311688311689\n",
    "0.6623376623376622\n",
    "\n",
    "dec\n",
    "0.6580086580086579\n",
    "0.6774891774891775\n",
    "0.6450216450216449\n",
    "\n",
    "all\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0c94344eef5dd42"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b38a2297b96909ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
