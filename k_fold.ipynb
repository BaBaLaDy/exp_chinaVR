{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn import svm, tree\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from merge_script import modify_first_column\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "import Calculate_Feature\n",
    "import os\n",
    "from spline import np_move_avg\n",
    "import pandas as pd\n",
    "\n",
    "def use_pca(featuer_data, n_components=5):\n",
    "    pca = PCA(n_components)\n",
    "    axis_fea = pca.fit_transform(featuer_data)  # 每个样本降为n_components维\n",
    "    fea = []\n",
    "    for raw in range(axis_fea.shape[0]):\n",
    "        for ele in axis_fea[raw, :]:\n",
    "            fea.append(ele)\n",
    "    return fea\n",
    "\n",
    "\n",
    "def axis_normalization(datalist, stage=1):\n",
    "    normalized_data = []\n",
    "    #datalist = np.array(datalist)\n",
    "    for data in datalist:\n",
    "        maximum = max(data)\n",
    "        minimum = min(data)\n",
    "        # print(\"maximum is:\",maximum,\"minimum is:\",minimum)\n",
    "        normalized_data.append([(item - minimum) / (maximum - minimum) * stage for item in data])\n",
    "    return np.array(normalized_data)\n",
    "\n",
    "\n",
    "def three_fuse(data):\n",
    "    axis_num = int(data.shape[0] / 3)\n",
    "    f_nd = []\n",
    "\n",
    "    for f_in in range(axis_num):\n",
    "        nd = []\n",
    "        index = f_in * 3\n",
    "        for i in range(data.shape[1]):\n",
    "            d = data[:, i]\n",
    "            fuse_data = math.sqrt(d[index] * d[index] + d[index + 1] * d[index + 1] + d[index + 2] * d[index + 2])\n",
    "            nd.append(fuse_data)\n",
    "        f_nd.append(nd)\n",
    "    return f_nd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:03:43.741025900Z",
     "start_time": "2023-12-27T04:03:43.705989Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/0.5', 'save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/0.7', 'save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/0.9', 'save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/1.1', 'save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/1.3', 'save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/1.5', 'save_data/RealData_Seg_byName/Effy', 'save_data/RealData_Seg_byName/Leafy', 'save_data/RealData_Seg_byName/Nick', 'save_data/RealData_Seg_byName/Qin', 'save_data/RealData_Seg_byName/Tonii', 'save_data/RealData_Seg_byName/Xu', 'save_data/RealData_Seg_byName/Yamamoto']\n"
     ]
    }
   ],
   "source": [
    "scale_list = [\"0.5\", \"0.7\", \"0.9\", \"1.1\", \"1.3\", \"1.5\"]\n",
    "# scale_list = [\"0.7\", \"0.9\", \"1.1\", \"1.3\", \"1.5\"]\n",
    "scale_list_conv = [\"0\", \"1\", \"2\", \"3\"]\n",
    "human_name = [\"Effy\", \"Leafy\", \"Nick\", \"Qin\", \"Tonii\", \"Xu\", \"Yamamoto\"]\n",
    "\n",
    "virtual_total_file = []\n",
    "real_total_file = []\n",
    "total_file = []\n",
    "virtual_data_path_3 = \"save_data/Pos_New_New_VirtualData_addPelvis_xyz_25_spline3_240/\"\n",
    "virtual_data_path_4 = \"save_data/Virtual_New_Conv_notrans_spline3_240/\"\n",
    "Real_data_path = \"save_data/RealData_Seg_byName/\"\n",
    "\n",
    "for scale in scale_list:\n",
    "    virtual_total_file.append(virtual_data_path_3 + scale)\n",
    "    total_file.append(virtual_data_path_3 + scale)\n",
    "#\n",
    "# for scale in scale_list_conv:\n",
    "#     virtual_total_file.append(virtual_data_path_4 + scale)\n",
    "#     total_file.append(virtual_data_path_4 + scale)\n",
    "\n",
    "for name in human_name:\n",
    "    real_total_file.append(Real_data_path + name)\n",
    "    total_file.append(Real_data_path + name)\n",
    "\n",
    "\n",
    "print(total_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:42:56.310744900Z",
     "start_time": "2023-12-27T04:42:56.281739300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552, 20)\n"
     ]
    }
   ],
   "source": [
    "label = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "LABEL_NUM = len(label)\n",
    "encode_feauture = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]  #[1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "# encode_feauture = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]  #[1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "Raw_Data = []\n",
    "Data_X = []\n",
    "Label_X = []\n",
    "PCA_Data = []\n",
    "\n",
    "# save_data/ori/pos_data/ankleTap_o_pos_merge_data.csv\n",
    "\n",
    "virtual_motion_type = ['ankle', 'highKnee', 'Knee_kick', 'reverseLunge', 'sideCrunch', 'sidetoside', 'warm']\n",
    "for fold_path in total_file:\n",
    "    for i in range(len(virtual_motion_type)):\n",
    "        motion = virtual_motion_type[i]\n",
    "        motion_file = glob.glob(os.path.join(fold_path + '/' + '*' + motion + '*', '*.csv'))\n",
    "        # print(motion_file)\n",
    "        for motion_frame in motion_file:\n",
    "            # print(motion_frame)\n",
    "\n",
    "            df = pd.read_csv(motion_frame, index_col=False, header=None, usecols= [9,10,11])\n",
    "            df = np.array(df).T\n",
    "            # print(df.shape[0])\n",
    "\n",
    "            # for k in range(df.shape[0]):\n",
    "            #     #df[:,k] = signal.filtfilt(b,a,df[:,k])\n",
    "            #     df[k, :] = np_move_avg(df[k, :], 30, mode='same')\n",
    "\n",
    "            fuse_df = three_fuse(df)\n",
    "            # plt.plot(fuse_df[0])\n",
    "            # pca = PCA(1)\n",
    "            # ld_signal = pca.fit_transform(df.T)\n",
    "            # print(ld_signal.shape)\n",
    "            # pca_signal = []\n",
    "            # for d in ld_signal:\n",
    "            #     pca_signal.append(float(d))\n",
    "            # pca_nor_data = []\n",
    "            # maximum = max(pca_signal)\n",
    "            # minimum = min(pca_signal)\n",
    "            # for item in pca_signal:\n",
    "            #     pca_nor_data.append((item - minimum) / (maximum - minimum) * 1)\n",
    "            nor_df = axis_normalization(fuse_df)  #.tolist()\n",
    "            # plt.plot(nor_df)\n",
    "            # print(nor_df.shape)\n",
    "            axis_fea = []\n",
    "            rd = []\n",
    "            # print(nor_df.shape[0])\n",
    "            for raw in range(nor_df.shape[0]):\n",
    "                tmd = nor_df[raw, :]\n",
    "                # print(tmd.shape)\n",
    "                rd.append(tmd)\n",
    "                cal_fea = Calculate_Feature.Get_Feature(tmd, encode_feauture)\n",
    "                fea = cal_fea.cal_result()\n",
    "                # print(len(fea))\n",
    "                #axis_fea.append(fea)\n",
    "                # print(len(axis_fea))\n",
    "                for f in fea:\n",
    "                    axis_fea.append(f)\n",
    "            # print(len(axis_fea))\n",
    "            Data_X.append(axis_fea)\n",
    "            Label_X.append(label[i])\n",
    "            Raw_Data.append(rd[0])\n",
    "            # PCA_Data.append(pca_nor_data)\n",
    "\n",
    "Virtual_Data = np.array(Data_X)\n",
    "print(Virtual_Data.shape)\n",
    "# print(Real_Data[0])\n",
    "# for i in range(Virtual_Data.shape[0]):\n",
    "#     Virtual_Data[i] = [0 if math.isnan(x) else x for x in Virtual_Data[i]]\n",
    "# plt.plot(Real_Data[])\n",
    "# print(Real_Data.shape)\n",
    "Row_Virtual_Data = np.array(Raw_Data)\n",
    "Raw_PCA_Data = np.array(PCA_Data)\n",
    "#pca = PCA(n_components = 2)\n",
    "#Real_Data = pca.fit_transform(Real_Data)\n",
    "Virtual_Label = np.array(Label_X)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:43:09.665839500Z",
     "start_time": "2023-12-27T04:42:57.837534200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:30:00.488689200Z",
     "start_time": "2023-12-27T04:30:00.460948Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(data,lab,n_fold = 5):\n",
    "    #n_fold = 3\n",
    "    k_fold = KFold(n_splits = n_fold, shuffle=True)\n",
    "    tmp_train, rf_test, svm_test, svm2_test = list(), list(), list(), list()\n",
    "    conf_mat = np.zeros((LABEL_NUM,LABEL_NUM))\n",
    "    #print(Data.shape)\n",
    "    rf = RandomForestClassifier(n_estimators = 30, random_state=42)\n",
    "    svc = svm.SVC(C=1000, kernel='rbf')\n",
    "    # clf = TimeSeriesSVC(C=5.4, kernel=\"gak\", gamma=\"auto\", max_iter=-1, n_jobs=-1, decision_function_shape='ovr')\n",
    "\n",
    "    index = 0\n",
    "    for train, test in k_fold.split(data):\n",
    "        #print(train)\n",
    "        index += 1\n",
    "        tmp_trx = []\n",
    "        tmp_try = []\n",
    "        tmp_raw = []\n",
    "        for titer in range(len(train)):\n",
    "            tmp_trx.append(data[train[titer]])\n",
    "            #tmp_raw.append(data2[train[titer]])\n",
    "            tmp_try.append(lab[train[titer]])\n",
    "        #print(tmp_trx)\n",
    "        rf.fit(tmp_trx, tmp_try)\n",
    "        svc.fit(tmp_trx, tmp_try)\n",
    "\n",
    "        #clf.fit(tmp_raw, tmp_try)\n",
    "\n",
    "        tmp_tex = []\n",
    "        tmp_te_raw_x = []\n",
    "        tmp_tey = []\n",
    "        for titer in range(len(test)):\n",
    "            tmp_tex.append(data[test[titer]])\n",
    "            #tmp_te_raw_x.append(data2[test[titer]])\n",
    "            tmp_tey.append(lab[test[titer]])\n",
    "\n",
    "            rf_predicted = rf.predict(tmp_tex)\n",
    "            svc_predicted = svc.predict(tmp_tex)\n",
    "            #svc2_predicted = clf.predict(tmp_te_raw_x)\n",
    "\n",
    "        rf_test.append(accuracy_score(tmp_tey,rf_predicted))\n",
    "        svm_test.append(accuracy_score(tmp_tey,svc_predicted))\n",
    "        #svm2_test.append(accuracy_score(tmp_tey,svc2_predicted))\n",
    "        #tmp_test.append(svc.score(tmp_tex, tmp_tey))\n",
    "        #print(\"result of svm classifier\", accuracy_score(tmp_tey,svc_predicted))\n",
    "        #print(\"result of random forest classifier\", accuracy_score(tmp_tey,rf_predicted))\n",
    "\n",
    "        # confusion matrix calculation\n",
    "        #print(confusion_matrix(tmp_tey,rf_predicted))\n",
    "        #conf_mat += confusion_matrix(tmp_tey,rf_predicted)\n",
    "\n",
    "    rf_score = sum(rf_test) / len(rf_test)\n",
    "    svm_score = sum(svm_test) / len(svm_test)\n",
    "    #svm2_score = sum(svm2_test) / len(svm2_test)\n",
    "\n",
    "    return svm_score,rf_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "(1985, 2)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(2)\n",
    "Virtual_Data_PCA = pca.fit_transform(Virtual_Data)\n",
    "Virtual_Data_PCA.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:41:21.802220100Z",
     "start_time": "2023-12-27T04:41:21.767878700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.8116980023501764 0.8755522914218566"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8286132143968468 0.9065677834249559\n"
     ]
    }
   ],
   "source": [
    "svm_result, rf_result = k_fold_cv(Virtual_Data, Virtual_Label,5)  # Virtual_Data_PCA\n",
    "print(svm_result, rf_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T05:14:46.283994100Z",
     "start_time": "2023-12-27T05:14:24.430117500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.609294947121034 0.5497708578143361"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49741154764488815 0.4613115910570871\n"
     ]
    }
   ],
   "source": [
    "svm_result, rf_result = k_fold_cv(Virtual_Data_PCA, Virtual_Label,5)  # Virtual_Data_PCA\n",
    "print(svm_result, rf_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T04:40:04.882043500Z",
     "start_time": "2023-12-27T04:39:43.701512200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
